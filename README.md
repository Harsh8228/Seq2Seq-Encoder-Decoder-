# Seq2Seq-Encoder-Decoder

🚀 Encoder-Decoder Example
A simple sequence-to-sequence model using TensorFlow/Keras for English-to-French translation! 
This project demonstrates an encoder-decoder architecture with LSTM layers for learning translation patterns from a tiny dataset.

✨ Features
- Tokenization & Padding for text preprocessing
- LSTM-based Encoder-Decoder Model
- Training & Inference Models for translation
- Small-scale dataset for quick experimentation
- Understand model limitations and expand upon them

🔍 Limitations
- Tiny dataset – not suitable for real-world translation
-  No attention mechanism – may struggle with long sequences

🎯 Further Improvements
- Improve translation accuracy!
- Add attention mechanism or expand the dataset.

Give this repo a ⭐ if you find it useful!
